{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:02.629155Z",
     "start_time": "2025-05-27T07:55:02.626051Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sympy.solvers.diophantine.diophantine import length\n",
    "\n",
    "from _config import PATH_RAW_DTU_SOLAR_STATION, PKL_PROCESSED_STEP1_DTU_SOLAR_STATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DTU Solar Station data\n",
    "The following code loads all csv files into one pandas dataframe, then it adds the timestamp as the index in pandas, then we ensure that the entire range of observations in a one minute interval is present and if not, then add it to the dataframe as nan values.\n",
    "\n",
    "Then we show some information about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:08.543782Z",
     "start_time": "2025-05-27T07:55:02.668342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5260805, 12)\n",
      "Index(['GHI', 'DNI', 'DHI', 'LWD', 'wind_speed_avg', 'wind_dir_avg',\n",
      "       'air_temperature', 'air_pressure', 'relative_humidity',\n",
      "       'rain_accumulation', 'rain_duration', 'rain_intensity'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 5260805 entries, 2015-01-01 00:00:00 to 2025-01-01 08:04:00\n",
      "Freq: min\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   GHI                float64\n",
      " 1   DNI                float64\n",
      " 2   DHI                float64\n",
      " 3   LWD                float64\n",
      " 4   wind_speed_avg     float64\n",
      " 5   wind_dir_avg       float64\n",
      " 6   air_temperature    float64\n",
      " 7   air_pressure       float64\n",
      " 8   relative_humidity  float64\n",
      " 9   rain_accumulation  float64\n",
      " 10  rain_duration      float64\n",
      " 11  rain_intensity     float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 521.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>DHI</th>\n",
       "      <th>LWD</th>\n",
       "      <th>wind_speed_avg</th>\n",
       "      <th>wind_dir_avg</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5031319.000</td>\n",
       "      <td>4965446.000</td>\n",
       "      <td>4993921.000</td>\n",
       "      <td>3073445.000</td>\n",
       "      <td>5086375.000</td>\n",
       "      <td>5086375.000</td>\n",
       "      <td>5086013.000</td>\n",
       "      <td>5086203.000</td>\n",
       "      <td>5086203.000</td>\n",
       "      <td>4963979.000</td>\n",
       "      <td>4963979.000</td>\n",
       "      <td>4963979.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>118.681</td>\n",
       "      <td>122.276</td>\n",
       "      <td>57.042</td>\n",
       "      <td>753.191</td>\n",
       "      <td>2.732</td>\n",
       "      <td>204.257</td>\n",
       "      <td>9.897</td>\n",
       "      <td>1007.485</td>\n",
       "      <td>73.333</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.953</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>207.283</td>\n",
       "      <td>261.393</td>\n",
       "      <td>92.284</td>\n",
       "      <td>9781.588</td>\n",
       "      <td>1.774</td>\n",
       "      <td>89.644</td>\n",
       "      <td>6.587</td>\n",
       "      <td>10.670</td>\n",
       "      <td>13.849</td>\n",
       "      <td>0.014</td>\n",
       "      <td>9.794</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.758</td>\n",
       "      <td>-12.520</td>\n",
       "      <td>-23.610</td>\n",
       "      <td>-7.325</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-10.100</td>\n",
       "      <td>958.200</td>\n",
       "      <td>12.200</td>\n",
       "      <td>-0.919</td>\n",
       "      <td>-0.946</td>\n",
       "      <td>-0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.149</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>-1.079</td>\n",
       "      <td>293.227</td>\n",
       "      <td>1.400</td>\n",
       "      <td>123.000</td>\n",
       "      <td>4.700</td>\n",
       "      <td>1001.000</td>\n",
       "      <td>64.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.305</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>3.613</td>\n",
       "      <td>324.874</td>\n",
       "      <td>2.400</td>\n",
       "      <td>231.000</td>\n",
       "      <td>9.500</td>\n",
       "      <td>1008.000</td>\n",
       "      <td>76.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>149.400</td>\n",
       "      <td>8.135</td>\n",
       "      <td>83.760</td>\n",
       "      <td>349.682</td>\n",
       "      <td>3.700</td>\n",
       "      <td>274.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>1014.000</td>\n",
       "      <td>84.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1690.000</td>\n",
       "      <td>1001.190</td>\n",
       "      <td>882.000</td>\n",
       "      <td>311300.000</td>\n",
       "      <td>26.700</td>\n",
       "      <td>359.000</td>\n",
       "      <td>31.600</td>\n",
       "      <td>1044.000</td>\n",
       "      <td>94.400</td>\n",
       "      <td>2.080</td>\n",
       "      <td>110.000</td>\n",
       "      <td>123.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               GHI          DNI          DHI          LWD  wind_speed_avg  \\\n",
       "count  5031319.000  4965446.000  4993921.000  3073445.000     5086375.000   \n",
       "mean       118.681      122.276       57.042      753.191           2.732   \n",
       "std        207.283      261.393       92.284     9781.588           1.774   \n",
       "min         -9.758      -12.520      -23.610       -7.325          -0.980   \n",
       "25%         -1.149       -0.303       -1.079      293.227           1.400   \n",
       "50%          3.305       -0.006        3.613      324.874           2.400   \n",
       "75%        149.400        8.135       83.760      349.682           3.700   \n",
       "max       1690.000     1001.190      882.000   311300.000          26.700   \n",
       "\n",
       "       wind_dir_avg  air_temperature  air_pressure  relative_humidity  \\\n",
       "count   5086375.000      5086013.000   5086203.000        5086203.000   \n",
       "mean        204.257            9.897      1007.485             73.333   \n",
       "std          89.644            6.587        10.670             13.849   \n",
       "min          -0.139          -10.100       958.200             12.200   \n",
       "25%         123.000            4.700      1001.000             64.900   \n",
       "50%         231.000            9.500      1008.000             76.800   \n",
       "75%         274.000           15.000      1014.000             84.400   \n",
       "max         359.000           31.600      1044.000             94.400   \n",
       "\n",
       "       rain_accumulation  rain_duration  rain_intensity  \n",
       "count        4963979.000    4963979.000     4963979.000  \n",
       "mean               0.001          1.953           0.065  \n",
       "std                0.014          9.794           0.857  \n",
       "min               -0.919         -0.946          -0.909  \n",
       "25%                0.000          0.000           0.000  \n",
       "50%                0.000          0.000           0.000  \n",
       "75%                0.000          0.000           0.000  \n",
       "max                2.080        110.000         123.400  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>DHI</th>\n",
       "      <th>LWD</th>\n",
       "      <th>wind_speed_avg</th>\n",
       "      <th>wind_dir_avg</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:01:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>264.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:02:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3</td>\n",
       "      <td>269.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:03:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>247.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>81.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:04:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2</td>\n",
       "      <td>228.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>81.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          GHI  DNI       DHI  LWD  wind_speed_avg  \\\n",
       "2015-01-01 00:00:00  0.000325  NaN -0.000002  NaN             5.0   \n",
       "2015-01-01 00:01:00       NaN  NaN       NaN  NaN             4.7   \n",
       "2015-01-01 00:02:00       NaN  NaN       NaN  NaN             3.3   \n",
       "2015-01-01 00:03:00       NaN  NaN       NaN  NaN             3.6   \n",
       "2015-01-01 00:04:00       NaN  NaN       NaN  NaN             2.2   \n",
       "\n",
       "                     wind_dir_avg  air_temperature  air_pressure  \\\n",
       "2015-01-01 00:00:00         278.0              4.8        1020.0   \n",
       "2015-01-01 00:01:00         264.0              4.8        1020.0   \n",
       "2015-01-01 00:02:00         269.0              4.8        1020.0   \n",
       "2015-01-01 00:03:00         247.0              4.8        1020.0   \n",
       "2015-01-01 00:04:00         228.0              4.8        1020.0   \n",
       "\n",
       "                     relative_humidity  rain_accumulation  rain_duration  \\\n",
       "2015-01-01 00:00:00               81.5                0.0            0.0   \n",
       "2015-01-01 00:01:00               81.6                0.0            0.0   \n",
       "2015-01-01 00:02:00               81.6                0.0            0.0   \n",
       "2015-01-01 00:03:00               81.7                0.0            0.0   \n",
       "2015-01-01 00:04:00               81.7                0.0            0.0   \n",
       "\n",
       "                     rain_intensity  \n",
       "2015-01-01 00:00:00             0.0  \n",
       "2015-01-01 00:01:00             0.0  \n",
       "2015-01-01 00:02:00             0.0  \n",
       "2015-01-01 00:03:00             0.0  \n",
       "2015-01-01 00:04:00             0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all CSV files in the path folder\n",
    "csv_files = list(PATH_RAW_DTU_SOLAR_STATION.glob(\"*.csv\"))\n",
    "\n",
    "# Read each CSV file and combine them into a single DataFrame\n",
    "dfs = [pd.read_csv(f) for f in csv_files]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df.set_index('Time(utc)', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Add missing indexes to the period (columns will be filled with NaN values.)\n",
    "full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq=\"1min\")\n",
    "df = df.reindex(full_range)\n",
    "df.sort_index(inplace=True)\n",
    "df_raw = df.copy()\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "display(df.describe().round(3), df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess DTU Solar Station Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove features\n",
    "Drop column ``LWD`` - a lot of missing data. \\\n",
    "Drop column ``rain_accumulation`` - based on manual reset time of hardware and thus not meaningful. \\\n",
    "Drop column ``GHI`` - This is a sum of DNI and DHI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:08.895265Z",
     "start_time": "2025-05-27T07:55:08.681068Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "# We observed alot of missing values in LWD\n",
    "df.drop(columns=['LWD'], inplace=True)\n",
    "df.drop(columns=['rain_accumulation'], inplace=True)\n",
    "df.drop(columns=['GHI'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set bad periods to NaN\n",
    "Certain periods in the time series data has bad data and can be seen in the previous time series plot. \\\n",
    "I set all feature to NaN for the periods to eliminate the use of them in the dataset - but keep the time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:09.002740Z",
     "start_time": "2025-05-27T07:55:08.921322Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df.copy()\n",
    "# display(df.loc['2021-01-05'].head())\n",
    "mask = (df.index > \"2021-01-04\") & (df.index < \"2021-02-23\")\n",
    "df.loc[mask] = np.nan\n",
    "# display(df.loc['2021-01-05'].head())\n",
    "\n",
    "# display(df.loc['2015-03-11'].head())\n",
    "mask = df.index < \"2015-03-12\"\n",
    "df.loc[mask] = np.nan\n",
    "# display(df.loc['2015-03-11'].head())\n",
    "\n",
    "# display(df.loc['2018-11-05'].head())\n",
    "mask = (df.index < \"2018-11-07\") & (df.index > \"2018-08-12\")\n",
    "df.loc[mask] = np.nan\n",
    "# display(df.loc['2018-11-05'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation/Interpolation\n",
    "Instead of discarding samples and thus potential data for training, then missing values for up to 15 points are imputed/interpolated using varying techniques in order to fill the data.\\\n",
    "If the missing values are greater than 15, then we discard the period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:09.377546Z",
     "start_time": "2025-05-27T07:55:09.042977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rr}\n",
      "\\toprule\n",
      "Missing Sequence Length & Number of Occurences \\\\\n",
      "\\midrule\n",
      "1 & 23 \\\\\n",
      "2 & 88 \\\\\n",
      "3 & 35 \\\\\n",
      "4 & 6 \\\\\n",
      "5 & 5 \\\\\n",
      "6 & 6 \\\\\n",
      "7 & 1 \\\\\n",
      "8 & 2 \\\\\n",
      "12 & 2 \\\\\n",
      "23 & 1 \\\\\n",
      "26 & 1 \\\\\n",
      "31 & 1 \\\\\n",
      "34 & 1 \\\\\n",
      "36 & 1 \\\\\n",
      "53 & 1 \\\\\n",
      "54 & 1 \\\\\n",
      "63 & 1 \\\\\n",
      "101 & 1 \\\\\n",
      "121 & 1 \\\\\n",
      "126 & 1 \\\\\n",
      "205 & 1 \\\\\n",
      "279 & 1 \\\\\n",
      "485 & 1 \\\\\n",
      "1146 & 1 \\\\\n",
      "4384 & 1 \\\\\n",
      "5630 & 1 \\\\\n",
      "5651 & 1 \\\\\n",
      "7070 & 1 \\\\\n",
      "12738 & 1 \\\\\n",
      "70898 & 1 \\\\\n",
      "77478 & 1 \\\\\n",
      "2036160 & 1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Sequence Length</th>\n",
       "      <th>Number of Occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12738</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>77478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2036160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Missing Sequence Length  Number of Occurences\n",
       "2                         1                    23\n",
       "3                         2                    88\n",
       "4                         3                    35\n",
       "10                        4                     6\n",
       "7                         5                     5\n",
       "28                        6                     6\n",
       "29                        7                     1\n",
       "26                        8                     2\n",
       "30                       12                     2\n",
       "31                       23                     1\n",
       "16                       26                     1\n",
       "15                       31                     1\n",
       "21                       34                     1\n",
       "11                       36                     1\n",
       "1                        53                     1\n",
       "13                       54                     1\n",
       "5                        63                     1\n",
       "18                      101                     1\n",
       "23                      121                     1\n",
       "24                      126                     1\n",
       "27                      205                     1\n",
       "9                       279                     1\n",
       "25                      485                     1\n",
       "12                     1146                     1\n",
       "17                     4384                     1\n",
       "20                     5630                     1\n",
       "22                     5651                     1\n",
       "19                     7070                     1\n",
       "8                     12738                     1\n",
       "6                     70898                     1\n",
       "14                    77478                     1\n",
       "0                   2036160                     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_imputed = df_raw.copy()\n",
    "\n",
    "# Create a boolean mask for rows with any NaN value.\n",
    "mask = df_imputed.isna().any(axis=1).values  # using .values for easy iteration\n",
    "\n",
    "# Identify contiguous gap groups (list of lists of integer positions)\n",
    "gap_groups = []\n",
    "current_group = []\n",
    "for i, is_nan in enumerate(mask):\n",
    "    if is_nan:\n",
    "        current_group.append(i)\n",
    "    else:\n",
    "        if current_group:\n",
    "            gap_groups.append(current_group)\n",
    "            current_group = []\n",
    "if current_group:\n",
    "    gap_groups.append(current_group)\n",
    "        \n",
    "length_counts = Counter(len(lst) for lst in gap_groups)\n",
    "occurence_df = pd.DataFrame.from_dict(length_counts, orient='index').reset_index()\n",
    "occurence_df.columns = ['Missing Sequence Length', 'Number of Occurences']\n",
    "occurence_df.sort_values(by='Missing Sequence Length', inplace=True)\n",
    "print(occurence_df.to_latex(index=False))\n",
    "occurence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:09.724392Z",
     "start_time": "2025-05-27T07:55:09.404073Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "\n",
    "def impute_nan_gaps(df):\n",
    "    \"\"\"\n",
    "    Impute gaps (rows with any NaN values) in a timeseries DataFrame\n",
    "    using different interpolation methods based on the gap length.\n",
    "\n",
    "    For each gap that is \"sandwiched\" by valid (non-NaN) rows:\n",
    "      - Gap length == 1: fill with the average of the previous and next valid rows.\n",
    "      - Gap length 2 to 5: use linear interpolation.\n",
    "      - Gap length 6 to 10: use polynomial interpolation (order 2).\n",
    "          (If sufficient surrounding points are not available, fallback to linear.)\n",
    "      - Gap length 11 to 15: use spline interpolation (order 2).\n",
    "          (Again, if not enough valid surrounding points are available, fallback to linear.)\n",
    "      - Gaps >15: leave the gap as-is.\n",
    "\n",
    "    Parameters:\n",
    "      df : pandas DataFrame with a timeseries index.\n",
    "\n",
    "    Returns:\n",
    "      df_imputed : a new DataFrame with the imputed values.\n",
    "    \"\"\"\n",
    "    # Work on a copy to avoid modifying the original DataFrame.\n",
    "    df_imputed = df.copy()\n",
    "\n",
    "    # Create a boolean mask for rows with any NaN value.\n",
    "    mask = df_imputed.isna().any(axis=1).values  # using .values for easy iteration\n",
    "\n",
    "    # Identify contiguous gap groups (list of lists of integer positions)\n",
    "    gap_groups = []\n",
    "    current_group = []\n",
    "    for i, is_nan in enumerate(mask):\n",
    "        if is_nan:\n",
    "            current_group.append(i)\n",
    "        else:\n",
    "            if current_group:\n",
    "                gap_groups.append(current_group)\n",
    "                current_group = []\n",
    "    if current_group:\n",
    "        gap_groups.append(current_group)\n",
    "\n",
    "    # Process each gap group\n",
    "    for group in gap_groups:\n",
    "        gap_length = len(group)\n",
    "        start = group[0]\n",
    "        end = group[-1]\n",
    "        # Ensure the gap is sandwiched by valid rows\n",
    "        if start == 0 or end == len(df_imputed) - 1:\n",
    "            continue\n",
    "        # Skip gaps longer than 15 rows\n",
    "        if gap_length > 15:\n",
    "            df_imputed.iloc[start:end + 1] = np.nan\n",
    "            continue\n",
    "\n",
    "        # Decide which interpolation method to use\n",
    "        if gap_length == 1:\n",
    "            method = 'average'\n",
    "        elif 2 <= gap_length <= 5:\n",
    "            method = 'linear'\n",
    "        elif 6 <= gap_length <= 10:\n",
    "            method = 'polynomial'\n",
    "        elif 11 <= gap_length <= 15:\n",
    "            method = 'spline'\n",
    "\n",
    "        # Process each column separately.\n",
    "        for col in df_imputed.columns:\n",
    "            # Check if any row in this gap is missing for the column.\n",
    "            # (It might be that only some columns are missing in the gap.)\n",
    "            gap_vals = df_imputed.iloc[start:end + 1][col]\n",
    "            if not gap_vals.isna().any():\n",
    "                continue  # nothing to fill for this column in this gap\n",
    "\n",
    "            # Get the endpoint values (assumed valid) for this column.\n",
    "            prev_val = df_imputed.iat[start - 1, df_imputed.columns.get_loc(col)]\n",
    "            next_val = df_imputed.iat[end + 1, df_imputed.columns.get_loc(col)]\n",
    "            if pd.isna(prev_val) or pd.isna(next_val):\n",
    "                # Safety check: if either endpoint is missing, skip imputation for this gap/column.\n",
    "                continue\n",
    "\n",
    "            if method == 'average':\n",
    "                # Gap length 1: fill with the average of the two endpoints.\n",
    "                fill_val = (prev_val + next_val) / 2\n",
    "                df_imputed.iat[start, df_imputed.columns.get_loc(col)] = fill_val\n",
    "\n",
    "            elif method == 'linear':\n",
    "                # Linear interpolation over the gap.\n",
    "                # For each missing row j (0-indexed in the gap), compute:\n",
    "                # interpolated_val = prev_val + (next_val - prev_val) * (j+1)/(gap_length+1)\n",
    "                for j in range(gap_length):\n",
    "                    interpolated_val = prev_val + (next_val - prev_val) * (j + 1) / (gap_length + 1)\n",
    "                    df_imputed.iat[start + j, df_imputed.columns.get_loc(col)] = interpolated_val\n",
    "\n",
    "            elif method == 'polynomial':\n",
    "                # Attempt quadratic interpolation (order=2).\n",
    "                # We need at least 3 points. We try to use:\n",
    "                #   - the row two steps before the gap (if available)\n",
    "                #   - the row immediately before the gap\n",
    "                #   - the row immediately after the gap\n",
    "                indices = []\n",
    "                values = []\n",
    "                if start - 2 >= 0:\n",
    "                    indices.append(start - 2)\n",
    "                    values.append(df_imputed.iat[start - 2, df_imputed.columns.get_loc(col)])\n",
    "                # Always include the row immediately before the gap.\n",
    "                indices.append(start - 1)\n",
    "                values.append(prev_val)\n",
    "                # Include the row immediately after the gap.\n",
    "                indices.append(end + 1)\n",
    "                values.append(next_val)\n",
    "\n",
    "                # If any of these are missing, fallback to linear interpolation.\n",
    "                if any(pd.isna(v) for v in values) or len(indices) < 3:\n",
    "                    for j in range(gap_length):\n",
    "                        interpolated_val = prev_val + (next_val - prev_val) * (j + 1) / (gap_length + 1)\n",
    "                        df_imputed.iat[start + j, df_imputed.columns.get_loc(col)] = interpolated_val\n",
    "                else:\n",
    "                    # Fit a quadratic polynomial.\n",
    "                    x = np.array(indices)\n",
    "                    y = np.array(values)\n",
    "                    coeffs = np.polyfit(x, y, 2)\n",
    "                    poly = np.poly1d(coeffs)\n",
    "                    # Fill in the gap rows by evaluating the polynomial at the corresponding positions.\n",
    "                    for idx in range(start, end + 1):\n",
    "                        df_imputed.iat[idx, df_imputed.columns.get_loc(col)] = poly(idx)\n",
    "\n",
    "            elif method == 'spline':\n",
    "                # Spline interpolation (order=2). We try to use two valid points before and after if possible.\n",
    "                indices = []\n",
    "                values = []\n",
    "                if start - 2 >= 0:\n",
    "                    indices.append(start - 2)\n",
    "                    values.append(df_imputed.iat[start - 2, df_imputed.columns.get_loc(col)])\n",
    "                if start - 1 >= 0:\n",
    "                    indices.append(start - 1)\n",
    "                    values.append(prev_val)\n",
    "                if end + 1 < len(df_imputed):\n",
    "                    indices.append(end + 1)\n",
    "                    values.append(next_val)\n",
    "                if end + 2 < len(df_imputed):\n",
    "                    indices.append(end + 2)\n",
    "                    values.append(df_imputed.iat[end + 2, df_imputed.columns.get_loc(col)])\n",
    "\n",
    "                # We need at least 3 points for spline interpolation.\n",
    "                if len(indices) < 3 or any(pd.isna(v) for v in values):\n",
    "                    # Fallback to linear if not enough valid points.\n",
    "                    for j in range(gap_length):\n",
    "                        interpolated_val = prev_val + (next_val - prev_val) * (j + 1) / (gap_length + 1)\n",
    "                        df_imputed.iat[start + j, df_imputed.columns.get_loc(col)] = interpolated_val\n",
    "                else:\n",
    "                    # Create a spline (k=2 for quadratic spline, s=0 forces interpolation).\n",
    "                    x = np.array(indices)\n",
    "                    y = np.array(values)\n",
    "                    spline = UnivariateSpline(x, y, k=2, s=0)\n",
    "                    for idx in range(start, end + 1):\n",
    "                        df_imputed.iat[idx, df_imputed.columns.get_loc(col)] = spline(idx)\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Suppose `df` is your timeseries DataFrame.\n",
    "df: pd.DataFrame = impute_nan_gaps(df)\n",
    "# Now `imputed_df` has gaps imputed for gap sizes 1-15 using different techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip invalid values\n",
    "Solar radiation is not negative. Thus ``DNI`` and ``DHI`` will be clipped to zero when values are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:09.812108Z",
     "start_time": "2025-05-27T07:55:09.757385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Values below 0 are set to 0 for GHI, DNI, and DHI\n",
    "df[['DNI', 'DHI']] = df[['DNI', 'DHI']].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Altitude\n",
    "The solar altitude is the angle of the sun above the horizon. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:24.881601Z",
     "start_time": "2025-05-27T07:55:09.850137Z"
    }
   },
   "outputs": [],
   "source": [
    "from astral import LocationInfo, Observer\n",
    "from astral.sun import elevation\n",
    "\n",
    "# Define location information for DTU Lyngby (Building 119)\n",
    "location = LocationInfo(\n",
    "    name=\"DTU Lyngby (Building 119)\",\n",
    "    region=\"Denmark\",\n",
    "    latitude=55.79064,\n",
    "    longitude=12.52505,\n",
    ")\n",
    "observer = Observer(location.latitude, location.longitude, 50)  # 50 meters above sea level\n",
    "\n",
    "\n",
    "# Define a function to compute solar altitude at a given datetime\n",
    "def compute_solar_altitude(dt):\n",
    "    return elevation(observer, dt)\n",
    "\n",
    "\n",
    "# Apply the function to each datetime in the index and add a new column\n",
    "df['solar_altitude'] = df.index.to_series().apply(compute_solar_altitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pvlib.location import Location\n",
    "location = Location(\n",
    "    latitude=55.79064,\n",
    "    longitude=12.52505,\n",
    "    altitude=50,  # in meters\n",
    "    name=\"DTU Lyngby (Building 119)\",\n",
    "    tz='Europe/Copenhagen'  # Adjust timezone appropriately\n",
    ")\n",
    "# Compute clear-sky Direct Normal Irradiance (DNI)\n",
    "clearsky = location.get_clearsky(times=df.index, model='ineichen')\n",
    "\n",
    "# Add DNI to your dataframe\n",
    "df['DNI_CLEAR_SKY'] = clearsky['dni']\n",
    "df['DHI_CLEAR_SKY'] = clearsky['dhi']\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set entire row to NaN\n",
    "To visualize and clearly see which datasamples are valid, then any row after preprocessing with a missing value will have all their feature set to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:24.990113Z",
     "start_time": "2025-05-27T07:55:24.899109Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.isnull().any(axis=1)] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set entire row to NaN if solar altitude is below 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:25.009050Z",
     "start_time": "2025-05-27T07:55:25.006882Z"
    }
   },
   "outputs": [],
   "source": [
    "# mask = df['solar_altitude'] < 0\n",
    "# df.loc[mask, :] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:25.041564Z",
     "start_time": "2025-05-27T07:55:25.039564Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessing for later loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T07:55:26.005794Z",
     "start_time": "2025-05-27T07:55:25.101689Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle(PKL_PROCESSED_STEP1_DTU_SOLAR_STATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNI</th>\n",
       "      <th>DHI</th>\n",
       "      <th>wind_speed_avg</th>\n",
       "      <th>wind_dir_avg</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>rain_intensity</th>\n",
       "      <th>solar_altitude</th>\n",
       "      <th>DNI_CLEAR_SKY</th>\n",
       "      <th>DHI_CLEAR_SKY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:01:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:02:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:03:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:04:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 08:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>235.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>990.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.553152</td>\n",
       "      <td>128.279617</td>\n",
       "      <td>1.768857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 08:01:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>227.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>989.8</td>\n",
       "      <td>85.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.641343</td>\n",
       "      <td>135.825312</td>\n",
       "      <td>1.925021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 08:02:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>280.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>990.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.729506</td>\n",
       "      <td>143.463186</td>\n",
       "      <td>2.085210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 08:03:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>989.9</td>\n",
       "      <td>85.6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.817622</td>\n",
       "      <td>151.178202</td>\n",
       "      <td>2.249067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01 08:04:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>242.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>989.9</td>\n",
       "      <td>85.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.905673</td>\n",
       "      <td>158.955946</td>\n",
       "      <td>2.416246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5260805 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DNI  DHI  wind_speed_avg  wind_dir_avg  air_temperature  \\\n",
       "2015-01-01 00:00:00  NaN  NaN             NaN           NaN              NaN   \n",
       "2015-01-01 00:01:00  NaN  NaN             NaN           NaN              NaN   \n",
       "2015-01-01 00:02:00  NaN  NaN             NaN           NaN              NaN   \n",
       "2015-01-01 00:03:00  NaN  NaN             NaN           NaN              NaN   \n",
       "2015-01-01 00:04:00  NaN  NaN             NaN           NaN              NaN   \n",
       "...                  ...  ...             ...           ...              ...   \n",
       "2025-01-01 08:00:00  0.0  0.0             5.2         235.0              8.3   \n",
       "2025-01-01 08:01:00  0.0  0.0             9.3         227.0              8.3   \n",
       "2025-01-01 08:02:00  0.0  0.0             2.1         280.0              8.3   \n",
       "2025-01-01 08:03:00  0.0  0.0             7.6         260.0              8.3   \n",
       "2025-01-01 08:04:00  0.0  0.0             9.3         242.0              8.3   \n",
       "\n",
       "                     air_pressure  relative_humidity  rain_duration  \\\n",
       "2015-01-01 00:00:00           NaN                NaN            NaN   \n",
       "2015-01-01 00:01:00           NaN                NaN            NaN   \n",
       "2015-01-01 00:02:00           NaN                NaN            NaN   \n",
       "2015-01-01 00:03:00           NaN                NaN            NaN   \n",
       "2015-01-01 00:04:00           NaN                NaN            NaN   \n",
       "...                           ...                ...            ...   \n",
       "2025-01-01 08:00:00         990.0               85.5           50.0   \n",
       "2025-01-01 08:01:00         989.8               85.6           60.0   \n",
       "2025-01-01 08:02:00         990.0               85.5           40.0   \n",
       "2025-01-01 08:03:00         989.9               85.6           50.0   \n",
       "2025-01-01 08:04:00         989.9               85.6           40.0   \n",
       "\n",
       "                     rain_intensity  solar_altitude  DNI_CLEAR_SKY  \\\n",
       "2015-01-01 00:00:00             NaN             NaN            NaN   \n",
       "2015-01-01 00:01:00             NaN             NaN            NaN   \n",
       "2015-01-01 00:02:00             NaN             NaN            NaN   \n",
       "2015-01-01 00:03:00             NaN             NaN            NaN   \n",
       "2015-01-01 00:04:00             NaN             NaN            NaN   \n",
       "...                             ...             ...            ...   \n",
       "2025-01-01 08:00:00             0.3        1.553152     128.279617   \n",
       "2025-01-01 08:01:00             0.4        1.641343     135.825312   \n",
       "2025-01-01 08:02:00             0.5        1.729506     143.463186   \n",
       "2025-01-01 08:03:00             0.5        1.817622     151.178202   \n",
       "2025-01-01 08:04:00             0.2        1.905673     158.955946   \n",
       "\n",
       "                     DHI_CLEAR_SKY  \n",
       "2015-01-01 00:00:00            NaN  \n",
       "2015-01-01 00:01:00            NaN  \n",
       "2015-01-01 00:02:00            NaN  \n",
       "2015-01-01 00:03:00            NaN  \n",
       "2015-01-01 00:04:00            NaN  \n",
       "...                            ...  \n",
       "2025-01-01 08:00:00       1.768857  \n",
       "2025-01-01 08:01:00       1.925021  \n",
       "2025-01-01 08:02:00       2.085210  \n",
       "2025-01-01 08:03:00       2.249067  \n",
       "2025-01-01 08:04:00       2.416246  \n",
       "\n",
       "[5260805 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
